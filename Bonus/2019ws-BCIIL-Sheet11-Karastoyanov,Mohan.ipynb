{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General rules:\n",
    " * For all figures that you generate, remember to add meaningful labels to the axes (including units), and provide a legend and colorbar, if applicable.\n",
    " * Do not hard code constants, like number of samples, number of channels, etc in your program. These values should always be determined from the given data. This way, you can easily use the code to analyse other data sets.\n",
    " * Do not use high-level functions from toolboxes like scikit-learn.\n",
    " * Before submitting, check your code by executing: Kernel -> Restart & run all.\n",
    " * Replace *Template* by your *FirstnameLastname* in the filename, or by *Lastname1Lastname2* if you work in pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI-IL - Exercise Sheet #11 BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import bci_minitoolbox as bci\n",
    "import bci_classifiers as cfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 282838)\n",
      "(280,)\n"
     ]
    }
   ],
   "source": [
    "fname = 'imagVPaw.npz'\n",
    "cnt, fs, clab, mnt, mrk_pos, mrk_class, mrk_className = bci.load_data(fname)\n",
    "print(cnt.shape)\n",
    "print(mrk_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CSP(epo, mrk_class):\n",
    "    ''' \n",
    "    Usage:\n",
    "        W, d = trainCSP(epo, mrk_class)\n",
    "    Parameters:\n",
    "        epo:   a 3D array of segmented signals (samples x channels x epochs)\n",
    "        mrk_class: a 1D array that assigns markers to classes (0, 1)\n",
    "    Returns:\n",
    "        W:     matrix of spatial filters\n",
    "        d:     vector of generalized Eigenvalues\n",
    "    '''\n",
    "    C = epo.shape[1]\n",
    "    X1 = np.reshape(np.transpose(epo[:,:,mrk_class==0], (1,0,2)), (C, -1))\n",
    "    S1 = np.cov(X1)\n",
    "    X2 = np.reshape(np.transpose(epo[:,:,mrk_class==1], (1,0,2)), (C, -1))\n",
    "    S2 = np.cov(X2)\t\n",
    "    d, W = scipy.linalg.eigh(a=S1, b=S1+S2)\n",
    "    return W, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(classifier_fcn, X, y, folds=10, verbose=False, feature_extraction=None):\n",
    "    '''\n",
    "    Synopsis:\n",
    "        loss_te, loss_tr= crossvalidation(classifier_fcn, X, y, folds=10, verbose=False)\n",
    "    Arguments:\n",
    "        classifier_fcn: handle to function that trains classifier as output w, b\n",
    "        X:              data matrix (features X epochs) or epochs (samples X channels x epochs) \n",
    "                                with feature_extraction producing a data matrix (features X epochs)\n",
    "        y:              labels with values 0 and 1 (1 x epochs)\n",
    "        folds:         number of folds\n",
    "        verbose:        print validation results or not\n",
    "        feature_extraction: a function producing a data matrix (features X epochs) out of epoched data\n",
    "    Output:\n",
    "        loss_te: value of loss function averaged across test data\n",
    "        loss_tr: value of loss function averaged across training data\n",
    "    '''\n",
    "    \n",
    "    if len(X.shape)==2:\n",
    "        nDim, nSamples = X.shape\n",
    "        feature_extraction=lambda X,Y,Z:X\n",
    "    elif len(X.shape)==3:\n",
    "        nT,nCh, nSamples = X.shape\n",
    "        if feature_extraction==None:\n",
    "            raise TypeError('For epoched data X, a feature extraction function has to be defined!')\n",
    "        \n",
    "    inter = np.round(np.linspace(0, nSamples, num=folds + 1)).astype(int)\n",
    "    perm = np.random.permutation(nSamples)\n",
    "    errTr = np.zeros([folds, 1])\n",
    "    errTe = np.zeros([folds, 1])\n",
    "\n",
    "    for ff in range(folds):\n",
    "        idxTe = perm[inter[ff]:inter[ff + 1] + 1]\n",
    "        idxTr = np.setdiff1d(range(nSamples), idxTe)\n",
    "        fv=feature_extraction(X,y,idxTr)\n",
    "        w, b = classifier_fcn(fv[:, idxTr], y[idxTr])\n",
    "        out = w.T.dot(fv) - b\n",
    "        errTe[ff] = cfy.loss_weighted_error(out[idxTe], y[idxTe])\n",
    "        errTr[ff] = cfy.loss_weighted_error(out[idxTr], y[idxTr])\n",
    "\n",
    "    if verbose:\n",
    "        print('{:5.1f} +/-{:4.1f}  (training:{:5.1f} +/-{:4.1f})  [using {}]'.format(errTe.mean(), errTe.std(),\n",
    "                                                                                     errTr.mean(), errTr.std(), \n",
    "                                                                                     classifier_fcn.__name__))\n",
    "    \n",
    "    return np.mean(errTe), np.mean(errTr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CSPlogvar(epo, mrk_class, idxTr, NumComp = 6):\n",
    "    ''' \n",
    "    Usage:\n",
    "        W, d = train_CSP_LDA(epo, mrk_class)\n",
    "    Parameters:\n",
    "        epo:   a 3D array of segmented signals (samples x channels x epochs)\n",
    "        mrk_class: a 1D array that assigns markers to classes (0, 1)\n",
    "        idxTr: indexes of the data to train CSP\n",
    "    Returns:\n",
    "        W:     matrix of spatial filters\n",
    "        d:     vector of generalized Eigenvalues\n",
    "    '''\n",
    "    W, d = train_CSP(epo[:,:, idxTr], mrk_class[idxTr])\n",
    "    selected_csps = np.flipud(np.argsort(np.maximum(d,1-d)))[:NumComp]\n",
    "    W_csp = W[:, selected_csps]\n",
    "    epo_csp = np.dot(W_csp.T, epo)\n",
    "    epo_csp = np.log(np.var(epo_csp,axis=1))\n",
    "    return epo_csp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Validation of CSP-based Classification  (10 BONUS points)\n",
    "This task is a continuation of the exercises on the sheet \\#08 and uses the same dataset. <br>\n",
    "Classification can be performed using log band-power features of the CSP filtered and segmented signals. Use the frequency-band, time-interval and the same selection of six CSP filters (as charaterized by the index) as on the previous sheet. Estimate the generalization error using the following three different procedures and compare the results:\n",
    "1. Determine the CSP filters on the first half of the epochs, calculate log band-power features from those epochs, train an LDA classifier and determine the classification error on those features (training error).\n",
    "2. Determine CSP filters and LDA classifier on the first half of the data as in (1), but determine the classification error on the second half of the data as required for a sound validation.\n",
    "3. Determine CSP filters on the first half of the data and determine the classification error by cross-validating LDA on the log band-power features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 51) (51,)\n",
      "[50  0 49 48  1 47]\n",
      "(51, 6)\n",
      "(6, 351, 140)\n",
      "(6, 140)\n",
      "  1.5 +/- 3.0  (training:  0.8 +/- 0.3)  [using train_LDA]\n",
      "[-8.36929932  4.47757869  0.29347242 -1.8282518   6.01006481 -1.70828983] 3.409931495873446\n",
      "(140,)\n",
      "training error for case 1: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Determine the CSP filters on the first half of the epochs, calculate log band-power features from those epochs,\n",
    "# train an LDA classifier and determine the classification error on those features (training error).\n",
    "\n",
    "band = [10.5, 13]\n",
    "ival = [1000, 4500]\n",
    "Wn = band / fs * 2\n",
    "b, a = sp.signal.butter(5, Wn, btype='bandpass')\n",
    "cnt_bp = sp.signal.lfilter(b, a, cnt)\n",
    "epo, epo_t = bci.makeepochs(cnt_bp, fs, mrk_pos, ival)\n",
    "\n",
    "halfind= int(mrk_pos.shape[0]/2)\n",
    "\n",
    "epo_1 = epo[:,:,:halfind]\n",
    "#print(epo_1.shape)\n",
    "mrk_class_1 = mrk_class[:halfind]\n",
    "#print(mrk_class_1.shape)\n",
    "\n",
    "W, d = train_CSP(epo_1, mrk_class_1)\n",
    "print(W.shape,d.shape)\n",
    "\n",
    "selected_csps = np.flipud(np.argsort(np.maximum(d,1-d)))[:6]\n",
    "print(selected_csps)\n",
    "\n",
    "W_csp = W[:, selected_csps]\n",
    "print(W_csp.shape)\n",
    "\n",
    "epo_csp_1 = np.dot(W_csp.T, epo_1)\n",
    "print(epo_csp_1.shape)\n",
    "\n",
    "epo_csp_1 = np.log(np.var(epo_csp_1,axis=1))\n",
    "print(epo_csp_1.shape)\n",
    "\n",
    "loss_test_1, loss_train_1 = cfy.crossvalidation(cfy.train_LDA, epo_csp_1, mrk_class_1, verbose = True)\n",
    "\n",
    "a1, b1 = cfy.train_LDA(epo_csp_1, mrk_class_1)\n",
    "print(a1,b1)\n",
    "\n",
    "out_1 = a1.T.dot(epo_csp_1) - b1\n",
    "print(out_1.shape)\n",
    "\n",
    "loss_1 = cfy.loss_weighted_error(out_1, mrk_class_1)\n",
    "print(\"training error for case 1:\", loss_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 51, 140)\n",
      "(6, 351, 140)\n",
      "(6, 140)\n",
      "[-10.12453781   2.7750425    0.09409441   0.39106803   4.34501542\n",
      "  -0.32733703] 4.649855406556106\n",
      "(140,)\n",
      "training error for case 2: 2.142857142857143\n"
     ]
    }
   ],
   "source": [
    "# Determine CSP filters and LDA classifier on the first half of the data as in (1),\n",
    "# but determine the classification error on the second half of the data as required for a sound validation.\n",
    "\n",
    "epo_2 = epo[:,:,halfind:]\n",
    "print(epo_2.shape)\n",
    "mrk_class_2 = mrk_class[halfind:]\n",
    "\n",
    "epo_csp_2 = np.dot(W_csp.T, epo_2)\n",
    "print(epo_csp_2.shape)\n",
    "\n",
    "epo_csp_2 = np.log(np.var(epo_csp_2,axis=1))\n",
    "print(epo_csp_2.shape)\n",
    "\n",
    "#loss_test_2, loss_train_2 = cfy.crossvalidation(cfy.train_LDA, epo_csp_2, mrk_class_2, verbose = True)\n",
    "a2, b2 = cfy.train_LDA(epo_csp_2, mrk_class_2)\n",
    "print(a2,b2)\n",
    "\n",
    "out_2 = a2.T.dot(epo_csp_2) - b2\n",
    "print(out_1.shape)\n",
    "\n",
    "#loss_2 = cfy.loss_weighted_error(out_1, mrk_class_2) # was it meant to show error between determined labels from 1st part with true labels from second part??\n",
    "loss_2 = cfy.loss_weighted_error(out_2, mrk_class_2)\n",
    "print(\"training error for case 2:\", loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.3 +/- 2.8  (training:  0.5 +/- 0.5)  [using train_LDA]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.2698412698412698, 0.47771857398873524)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine CSP filters on the first half of the data and \n",
    "# determine the classification error by cross-validating LDA on the log band-power features.\n",
    "\n",
    "crossvalidation(cfy.train_LDA, epo_1, mrk_class_1, folds=10, verbose=True, feature_extraction=train_CSPlogvar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
